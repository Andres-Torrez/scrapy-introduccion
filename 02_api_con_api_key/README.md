# Escenario 2 â€“ Scraping con API pÃºblica usando API Key

En este escenario se muestra cÃ³mo utilizar **Scrapy** para consumir una **API pÃºblica que requiere autenticaciÃ³n mediante una API Key**.

Este tipo de APIs es muy comÃºn en proyectos reales, ya que permite a las plataformas
controlar el uso, evitar abusos y medir consumo.

## ğŸ“Œ Â¿QuÃ© se aprende en este escenario?

- QuÃ© es una API Key y para quÃ© se usa
- CÃ³mo autenticar requests en una API
- CÃ³mo consumir APIs oficiales con Scrapy
- Buenas prÃ¡cticas de seguridad (no subir claves a GitHub)

## ğŸ› ï¸ Requisitos

Antes de comenzar necesitas:

- Python 3 instalado
- Visual Studio Code
- Cuenta en The Movie Database (TMDB)
- Una API Key vÃ¡lida
  

## ğŸ”‘ Paso 1: Obtener una API Key

Para este ejemplo utilizamos la API de **The Movie Database (TMDB)**.

Pasos:
1. Crear una cuenta en https://www.themoviedb.org
2. Ir a Settings â†’ API
3. Solicitar una API Key
4. Copiar la clave generada

âš ï¸ Importante:  
La API Key **no debe subirse a repositorios pÃºblicos**.

## ğŸ“ Paso 1: Crear la carpeta del proyecto

Creamos una carpeta para este escenario y la abrimos en Visual Studio Code:

```bash
mkdir scrapy_api_key
cd scrapy_api_key
```


---

## ğŸ§ª Paso 2: Crear y activar el entorno virtual

Creamos un entorno virtual para aislar las dependencias del proyecto.

```bash
python -m venv venv
```

### Activar el entorno virtual

Una vez creado el entorno virtual, es necesario activarlo para que las dependencias
se instalen y ejecuten Ãºnicamente dentro del proyecto.

#### En Windows
```bash
venv\Scripts\activate
```

#### En macOS o Linux
```bash
source venv/bin/activate
```


---

## ğŸ“¦ Paso 3: Instalar Scrapy

Con el entorno virtual activo, instalamos Scrapy:

```bash
pip install scrapy
```


---

## ğŸ—ï¸ Paso 4: Crear el proyecto Scrapy

Creamos la estructura base del proyecto usando Scrapy:

```bash
scrapy startproject peliculas_tmdb
cd peliculas_tmdb
```

---

## ğŸ•·ï¸ Paso 5: Crear el Spider

Creamos un spider que se conectarÃ¡ a la API de TMDB:

```bash
scrapy genspider top_2025 api.themoviedb.org
```


---

## ğŸ§  Paso 6: CÃ³digo del Spider (API con Key)

En este paso definimos la lÃ³gica del spider.
Scrapy se conecta a la API oficial de TMDB utilizando una **API Key** y procesa la respuesta en formato JSON.

```python
import scrapy
import json

class Top2025Spider(scrapy.Spider):
    name = "top_2025"

    api_key = "TU_API_KEY_AQUI"

    def start_requests(self):
        url = (
            "https://api.themoviedb.org/3/discover/movie"
            f"?api_key={self.api_key}"
            "&primary_release_year=2025"
            "&sort_by=vote_average.desc"
            "&vote_count.gte=500"
        )
        yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        data = json.loads(response.text)

        for peli in data["results"]:
            yield {
                "titulo": peli["title"],
                "fecha": peli["release_date"],
                "rating": peli["vote_average"],
                "votos": peli["vote_count"]
            }
```

âš ï¸ Recuerda reemplazar TU_API_KEY_AQUI por tu propia clave.

---

## â–¶ï¸ Paso 7: Ejecutar el Spider

Ejecutamos el spider desde la carpeta donde se encuentra el archivo `scrapy.cfg`:

```bash
scrapy crawl top_2025 -o top_peliculas_2025.json
```


---

## ğŸ“„ Resultado

Se genera el archivo `top_peliculas_2025.json` que contiene informaciÃ³n como:
- TÃ­tulo de la pelÃ­cula
- Fecha de estreno
- Rating promedio
- Cantidad de votos


## âœ… ConclusiÃ³n

Este escenario demuestra cÃ³mo Scrapy puede utilizarse para consumir **APIs oficiales con autenticaciÃ³n**.
Este enfoque es mÃ¡s estable, rÃ¡pido y profesional que el scraping de HTML, y es ampliamente usado en proyectos reales.


